# For licensing see accompanying LICENSE file.
# Copyright (C) 2024 Apple Inc. All Rights Reserved.
"""Agent role for Gorilla."""

import ast
import json
import keyword
import os
from typing import Any, Iterable, List, Literal, Optional, Union, cast

from openai import NOT_GIVEN, NotGiven, OpenAI
from openai.types.chat import ChatCompletionToolParam
from openai.types.chat.chat_completion import ChatCompletion, Choice
from openai.types.chat.chat_completion_message import ChatCompletionMessage
from openai.types.chat.chat_completion_message_tool_call import (
    ChatCompletionMessageToolCall,
    Function,
)
from openai.types.completion import Completion
from openai.types.completion_choice import CompletionChoice
from requests.exceptions import HTTPError
from tenacity import (
    retry,
    retry_if_exception_type,
    stop_after_attempt,
    wait_random_exponential,
)

from tool_sandbox.common.execution_context import RoleType, get_current_context
from tool_sandbox.common.message_conversion import (
    Message,
    openai_tool_call_to_python_code,
    to_openai_messages,
)
from tool_sandbox.common.tool_conversion import convert_to_openai_tools
from tool_sandbox.roles.base_role import BaseRole


# From https://github.com/ShishirPatil/gorilla/blob/main/openfunctions/utils/python_parser.py
def process_ast_node(node: Union[ast.Call, ast.Expr]) -> Union[str, Any]:
    """Parse AST node."""
    # Check if the node is a function call
    if isinstance(node, ast.Call):
        # Return a string representation of the function call
        return ast.unparse(node)
    else:
        # Convert the node to source code and evaluate to get the value
        node_str = ast.unparse(node)
        return eval(node_str)


# From https://github.com/ShishirPatil/gorilla/blob/main/openfunctions/utils/python_parser.py
def parse_python_function_call(call_str: str) -> dict[str, Any]:
    """Parse response function call as Python."""
    tree = ast.parse(call_str)
    expr = tree.body[0]

    call_node = expr.value  # type: ignore
    function_name = (
        call_node.func.id
        if isinstance(call_node.func, ast.Name)
        else str(call_node.func)
    )

    parameters = {}
    nonameparam = []

    # Process positional arguments
    for arg in call_node.args:
        nonameparam.append(process_ast_node(arg))

    # Process keyword arguments
    for kw in call_node.keywords:
        parameters[kw.arg] = process_ast_node(kw.value)

    if nonameparam:
        parameters["None"] = nonameparam

    function_dict = {"name": function_name, "arguments": parameters}
    return function_dict


# Adapted from https://github.com/ShishirPatil/gorilla/blob/main/openfunctions/openfunctions_utils.py
# We have removed the code for parsing Java and JavaScript functions since `ToolSandbox`
# only uses Python tools.
def _parse_function_call(call: str) -> Optional[dict[str, Any]]:
    """Parse the response string.

    This is temporary. The long term solution is to union all the
    types of the parameters from the user's input function definition,
    and check which language is a proper super set of the union type.
    """
    return parse_python_function_call(call)


FN_CALL_DELIMITER = "<<function>>"


# Adapted from https://github.com/ShishirPatil/gorilla/blob/main/openfunctions/openfunctions_utils.py
def _strip_function_calls(content: str) -> list[str]:
    """Split the content by the function call delimiter and remove empty strings."""
    # Fix: Removed [:2]
    return [
        element.strip()
        for element in content.split(FN_CALL_DELIMITER)
        if element.strip()
    ]


# Adapted from https://huggingface.co/gorilla-llm/gorilla-openfunctions-v2#running-openfunctions-locally
def format_response(response_in: str) -> list[dict[str, Any]]:
    """Formats the response from the OpenFunctions model.

    Args:
      response_in (str): The response generated by the LLM.

    Returns:
      The function call(s) extracted from the response. Can be an empty list.
    """
    function_call_dicts: list[dict[str, Any]] = []
    response_parts = _strip_function_calls(response_in)
    for function_call in response_parts:
        function_call_dict = _parse_function_call(function_call)
        if function_call_dict is not None:
            function_call_dicts.append(function_call_dict)
    return function_call_dicts


def to_chat_completion_message(choice: CompletionChoice) -> ChatCompletionMessage:
    """Convert the `CompletionChoice` to a `ChatCompletionMessage` with tool calls."""
    content = choice.text
    tool_calls = None
    try:
        function_call_dicts = format_response(choice.text)
        if len(function_call_dicts) > 0:
            content = ""
            tool_calls = [
                ChatCompletionMessageToolCall(
                    id=f"call_{i}",
                    function=Function(
                        name=func_desc["name"],
                        arguments=json.dumps(func_desc["arguments"]),
                    ),
                    type="function",
                )
                for i, func_desc in enumerate(function_call_dicts)
            ]
    except Exception:
        # If there was an error parsing the tool call or if the message contains no tool
        # call we just return the original text response.
        pass

    return ChatCompletionMessage(
        content=content,
        role="assistant",
        tool_calls=tool_calls,
    )


def completion_to_chat_completion(response: Completion) -> ChatCompletion:
    """Convert the `Completion` to a `ChatCompletion` object with tool calls."""
    assert (
        len(response.choices) > 0
    ), f"The `choices` list of the response must not be empty:\n{response}"
    assert len(response.choices) == 1, (
        f"Only a single choice is currently supported but got {len(response.choices)}:"
        f"\n{response}"
    )
    choices = [
        Choice(
            finish_reason=response.choices[0].finish_reason,
            index=response.choices[0].index,
            message=to_chat_completion_message(choice),
        )
        for choice in response.choices
    ]
    completion_response = ChatCompletion(
        id=response.id,
        choices=choices,
        created=response.created,
        model=response.model,
        object="chat.completion",
    )
    return completion_response


# From https://huggingface.co/gorilla-llm/gorilla-openfunctions-v2#running-openfunctions-locally
def get_prompt(user_query: str, functions: list[ChatCompletionToolParam]) -> str:
    """Generate a conversation prompt based on the user's query and a list of functions.

    Args:
      user_query: The user's query.
      functions (list): A list of functions to include in the prompt.

    Returns:
      str: The formatted conversation prompt.
    """
    system = (
        "You are an AI programming assistant, utilizing the Gorilla LLM model, developed by Gorilla"
        " LLM, and you only answer questions related to computer science. For politically sensitive"
        " questions, security and privacy issues, and other non-computer science questions, you"
        " will refuse to answer."
    )
    if len(functions) == 0:
        return f"{system}\n### Instruction: <<question>> {user_query}\n### Response: "
    functions_string = json.dumps(functions)
    return (
        f"{system}\n### Instruction: <<function>>{functions_string}\n"
        f"<<question>>{user_query}\n### Response: "
    )


def _sanitize_messages(
    openai_messages: list[
        dict[
            Literal["role", "content", "tool_call_id", "name", "tool_calls"],
            Any,
        ]
    ],
) -> list[
    dict[
        Literal["role", "content", "tool_call_id", "name", "tool_calls"],
        Any,
    ]
]:
    """Sanitize tool names in the given messages.

    Change all function arguments to satisfy Python requirements:
    * Only alphanumeric characters + '_'
    * Start with alphabetic character or '_'

    Args:
        openai_messages: Messages in the OpenAI format.
    Returns:
        Sanitized messages.
    """

    def _sanitize_tool_call(tool_call: dict[str, Any]) -> dict[str, Any]:
        arguments = json.loads(tool_call["function"]["arguments"])
        new_arguments = {
            sanitize_python_name(argname): argdesc
            for argname, argdesc in arguments.items()
        }
        tool_call["function"]["arguments"] = json.dumps(new_arguments)
        return tool_call

    def _sanitize_message(
        message: dict[
            Literal["role", "content", "tool_call_id", "name", "tool_calls"],
            Any,
        ],
    ) -> dict[
        Literal["role", "content", "tool_call_id", "name", "tool_calls"],
        Any,
    ]:
        if "tool_calls" in message:
            new_tool_calls = [
                _sanitize_tool_call(tool_call=tc) for tc in message["tool_calls"]
            ]
            message["tool_calls"] = new_tool_calls
        return message

    new_messages = [_sanitize_message(message=message) for message in openai_messages]
    return new_messages


def sanitize_python_name(varname: str) -> str:
    """Sanitize an arbitrary string to conform to Python rules."""

    def replace_non_alphanumeric(name: str) -> str:
        if not name.isalnum():
            alphanumeric_name = "".join(c if c.isalnum() else "_" for c in name)
            return alphanumeric_name
        return name

    def prefix_keyword(name: str) -> str:
        if keyword.iskeyword(name):
            return "_" + name
        return name

    def prefix_leading_digit(name: str) -> str:
        if name[0].isdigit():
            return "_" + name
        return name

    sanitized_name = replace_non_alphanumeric(varname)
    sanitized_name = prefix_keyword(sanitized_name)
    sanitized_name = prefix_leading_digit(sanitized_name)

    return sanitized_name


def _sanitize_tools(
    openai_tools: Iterable[ChatCompletionToolParam],
) -> list[ChatCompletionToolParam]:
    """Sanitize tool definitions.

    Change all function arguments to satisfy Python requirements:
    * Only alphanumeric characters + '_'
    * Start with alphabetic character or '_'

    Args:
        openai_tools: Tools in the OpenAI format.
    Returns:
        The sanitized tool definitions.
    """

    def _sanitize_tool_defn(
        tool_defn: ChatCompletionToolParam,
    ) -> ChatCompletionToolParam:
        # OpenAI's type hint for `parameters` is `Dict[str, object]`.
        properties = cast(
            dict[str, Any], tool_defn["function"]["parameters"]["properties"]
        )
        new_properties = {
            sanitize_python_name(propname): propdesc
            for propname, propdesc in properties.items()
        }
        tool_defn["function"]["parameters"]["properties"] = new_properties

        required = cast(list[str], tool_defn["function"]["parameters"]["required"])
        new_required = [sanitize_python_name(r) for r in required]
        tool_defn["function"]["parameters"]["required"] = new_required

        return tool_defn

    return [_sanitize_tool_defn(tdef) for tdef in openai_tools]


class GorillaAPIAgent(BaseRole):
    """Agent role for Gorilla."""

    role_type: RoleType = RoleType.AGENT
    model_name: str

    def __init__(self, model_name: str) -> None:
        super().__init__()

        self.model_name = model_name
        assert (
            "OPENAI_BASE_URL" in os.environ
        ), "The `OPENAI_BASE_URL` environment variable must be set."
        self.client = OpenAI(api_key="EMPTY")

    def respond(self, ending_index: Optional[int] = None) -> None:
        """Reads a List of messages and attempt to respond with a Message

        Specifically, interprets system, user, execution environment messages and sends out NL response to user, or
        code snippet to execution environment.

        Message comes from current context, the last k messages should be directed to this role type
        Response are written to current context as well. n new messages, addressed to appropriate recipient
        k != n when dealing with parallel function call and responses. Parallel function call are expanded into
        individual messages, parallel function call responses are combined as 1 OpenAI API request

        Args:
            ending_index:   Optional index. Will respond to message located at ending_index instead of most recent one
                            if provided. Utility for processing system message, which could contain multiple entries
                            before each was responded to

        Raises:
            KeyError:   When the last message is not directed to this role
        """
        messages: List[Message] = self.get_messages(ending_index=ending_index)
        response_messages: List[Message] = []
        self.messages_validation(messages=messages)
        # Keeps only relevant messages
        messages = self.filter_messages(messages=messages)
        # Does not respond to System
        if messages[-1].sender == RoleType.SYSTEM:
            return
        # Get OpenAI tools if most recent message is from user
        available_tools = self.get_available_tools()
        available_tool_names = set(available_tools.keys())
        openai_tools = (
            convert_to_openai_tools(available_tools)
            if messages[-1].sender == RoleType.USER
            or messages[-1].sender == RoleType.EXECUTION_ENVIRONMENT
            else NOT_GIVEN
        )
        # We need a cast here since `convert_to_openai_tool` returns a plain dict, but
        # `ChatCompletionToolParam` is a `TypedDict`.
        openai_tools = cast(
            Union[Iterable[ChatCompletionToolParam], NotGiven],
            openai_tools,
        )
        # Convert to OpenAI messages.
        current_context = get_current_context()
        openai_messages, _ = to_openai_messages(messages)
        # Call model
        gorilla_response = self.model_inference(
            openai_messages=openai_messages, openai_tools=openai_tools
        )

        # Parse response
        openai_response = completion_to_chat_completion(gorilla_response)
        openai_response_message = openai_response.choices[0].message

        # Message contains no tool call, aka addressed to user
        if openai_response_message.tool_calls is None:
            assert openai_response_message.content is not None
            response_messages = [
                Message(
                    sender=self.role_type,
                    recipient=RoleType.USER,
                    content=openai_response_message.content,
                )
            ]
        else:
            assert openai_tools is not NOT_GIVEN
            for tool_call in openai_response_message.tool_calls:
                # The response contains the agent facing tool name so we need to get
                # the execution facing tool name when creating the Python code.
                execution_facing_tool_name = (
                    current_context.get_execution_facing_tool_name(
                        tool_call.function.name
                    )
                )
                response_messages.append(
                    Message(
                        sender=self.role_type,
                        recipient=RoleType.EXECUTION_ENVIRONMENT,
                        content=openai_tool_call_to_python_code(
                            tool_call,
                            available_tool_names,
                            execution_facing_tool_name=execution_facing_tool_name,
                        ),
                        openai_tool_call_id=tool_call.id,
                        openai_function_name=tool_call.function.name,
                    )
                )
        self.add_messages(response_messages)

    @retry(
        wait=wait_random_exponential(multiplier=1, max=40),
        stop=stop_after_attempt(3),
        retry=retry_if_exception_type(HTTPError),
    )
    def model_inference(
        self,
        openai_messages: list[
            dict[
                Literal["role", "content", "tool_call_id", "name", "tool_calls"],
                Any,
            ]
        ],
        openai_tools: Union[Iterable[ChatCompletionToolParam], NotGiven],
    ) -> Completion:
        """Run Gorilla model inference

        Args:
            openai_messages:    List of OpenAI API format messages
            openai_tools:       List of OpenAI API format tools definition

        Returns:
            OpenAI API chat completion object
        """
        openai_messages = _sanitize_messages(openai_messages)
        openai_tools = _sanitize_tools(openai_tools) if openai_tools else []

        user_query = ""
        for msg in openai_messages:
            if msg["role"] == "user":
                user_query = msg["content"]
        prompt = get_prompt(user_query, openai_tools)

        gorilla_response = self.client.completions.create(
            prompt=prompt,
            model=self.model_name,
            max_tokens=1024,
            temperature=0.0,
        )
        return gorilla_response
